import asyncio
import nest_asyncio
import streamlit as st
from langchain.schema.runnable import RunnableSequence
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_experimental.text_splitter import SemanticChunker
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaLLM as Ollama
from langchain.prompts import PromptTemplate
from langchain.chains.combine_documents.stuff import create_stuff_documents_chain
from langchain.chains import RetrievalQA
from langchain_huggingface.embeddings import HuggingFaceEmbeddings

# Ensure proper event loop handling
try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())

nest_asyncio.apply()

# Streamlit UI
st.title("ğŸ“„ RAG ç³»çµ±èˆ‡ DeepSeek R1 å’Œ Ollama")

uploaded_file = st.file_uploader("åœ¨é€™è£¡ä¸Šå‚³ä½ çš„ PDF æ–‡ä»¶", type="pdf")

if uploaded_file:
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.getvalue())

    loader = PDFPlumberLoader("temp.pdf")
    docs = loader.load()
    embeddings = HuggingFaceEmbeddings()
    text_splitter = SemanticChunker(embeddings=embeddings)
    documents = text_splitter.split_documents(docs)

    embedder = HuggingFaceEmbeddings()
    vector = FAISS.from_documents(documents, embedder)
    retriever = vector.as_retriever(search_type="similarity", search_kwargs={"k": 3})

    llm = Ollama(model="deepseek-r1:8b")

    prompt = """
    ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œã€‚
    ä¸Šä¸‹æ–‡: {context}
    å•é¡Œ: {question}
    ç­”æ¡ˆ:"""

    QA_PROMPT = PromptTemplate.from_template(prompt)

    # Replace LLMChain with RunnableSequence
    llm_chain = QA_PROMPT | llm
    combine_documents_chain = create_stuff_documents_chain(
        llm=llm_chain, 
        prompt=QA_PROMPT, 
        document_variable_name="context"
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True
    )

    user_input = st.text_input("è©¢å•ä½ çš„æ–‡ä»¶å•é¡Œï¼š")

    if user_input:
        response = qa.invoke({"query": user_input})
        st.write("**å›æ‡‰ï¼š**")
        st.write(response["result"])  # Display the main result
        st.write("**ä¾†æºæ–‡ä»¶ï¼š**")
        for doc in response["source_documents"]:
            st.write(doc.page_content)  # Display the content of the source documents